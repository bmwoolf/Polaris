Computational scAAVengr MVP that moves 99% of the wet lab work to being computational

Goal: simulate cell type x AAV serotype transduction rates from capsid sequence + promoter identity, entirely computationally

Key components:
1. cell model: model the type of cell in memory that we are going to use (animal species x organ x location in organ) 
2. capsid to tropism prediction: model that predicts transduction efficiency for each cell type given the capsid amino acid sequence and promoter type
3. synthetic scRNA-seq data generation (that may be a proxy for the cell type we are testing the AAV capsid in): create/obtain realistic scRNA-seq datasets with barcode integration, based on predicted transduction rates
4. reference genome building: add barcode sequences to an existing reference genome for read mapping
5. analysis pipeline: MLops that stitches it all together and performs read alignment, clustering, dimensionality reduction, and plotting to reproduce the same outputs as the wet-lab pipeline

System layout:
inputs/
  capsids.fasta           # VP protein sequences of AAV variants
  barcodes.csv            # serotype and 8-nt barcode mapping
  promoters.yaml          # metadata for promoters (CAG, CMV, RHO)
  atlas/                  # single-cell reference with cell-type annotations

pipeline/
  01_cell_model_embeddings/ # embeddings of cell
  01_capsid_embeddings/     # embeddings from protein language model
  02_tropism_prediction/    # model inference for cell type × serotype
  03_synthetic_scRNAseq/    # scRNA-seq simulation with barcodes
  04_reference_build/       # augmented FASTA+GTF with barcodes
  05_alignment_analysis/    # STARsolo/Scanpy, clustering, UMAP
  06_reporting/             # heatmaps, metrics, summary plots

outputs/
  predicted_tropism.csv
  synthetic_scRNAseq.h5ad
  figures/

Public datasets:
- single cell atlases of brain and retina for different species, with cell type annotations and marker genes (Arc Virtual Cell Atlas + Arc State)
- published AAV tropism data for common serotypes (AAV2, AAV6, DJ, Anc80)
- promoter activity for CAG, CMV, and RHO in the different cell types

Steps:
1. get retinal + cerebral cell data- type annotations, embeddings, markets
2. get capsid -> tissue preferences (AAV2/6/DJ/Anc80)
3. get promoter priors CAG/CMV/RHO relative strength by cell type
4. implement model architecture
    > cell encoder: use scDesign3/State/Virtual Cell Atlas/scDiffusion seeded with retinal/brain atalases, harmonize an ensemble via Scanorama/BBKNN/scVI (not sure what this will entail yet)
        > pull Arc Atlas cells → build cell-type embeddings
        > import retina atlas (HCA retina v1.0 or Cell/NC papers) → integrate
            - https://data.humancellatlas.org/hca-bio-networks/eye/atlases/retina-v1-0?utm_source=chatgpt.com
        > run State on matched cell states with your “payload context” → get Δ expression
        > compose baseline + Δ expression → simulate per-cell profiles; tag AAV barcodes by predicted tropism; produce CellType × Serotype heatmaps
    > capsid encoder: ESM-2 embeddings of VP3 sequence
    > promoter encoder: one-hot + learned weight per cell type 
    > Head A (lookup prior): rule-based logits from literature
    > Head B (metric learner): gradient-boosted trees on embeddings -> tissue logits
    > Head C (transfer net): small MLP trained to align A/B to atlas distribution 
    > Blend: calibrated stacking (logistic) + temperature scaling -> per cell-type rate
    > Inject AAV-barcoded features per cell using predicted rates + realistic dropout/error
    > Analysis: STARsolo/ScanPy to recreate clustering, t-SNE/UMAP, and CellType x Serotype heatmaps, exactly as scAAVengr showed them

Quantitative metrics to aim for:
- heatmap fidelity: correlation to priors >= 0.6 across cell types
- uncertainty: per cell type CV <= 0.225 across samples 
- synthetic cell realism: scRNA-seq quality (library size, gene counts, dropouts) within 10% of atlas, kNN structure preservation >= 0.8
- ablations: removing promoter/capsid embeddings must degrade AUC >= 0.5

Tech stack:
- PyTorch, scikit-learn, Scanpy, anndata
- Models: ESM-2, XGBoost/LightGBM, small MLP
- Simulation: scDesign3 Python port, DDPM if needed 
- Pipelines: Nextflow/Snakemake, Docker
- Repro: Hydra configs, seed management, MLFlow for runs, HuggingFace for weights